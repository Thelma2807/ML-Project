{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQofHmZ7icTm"
   },
   "outputs": [],
   "source": [
    "# --- 0. Imports & config ---\n",
    "import os, math, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "\n",
    "# Dossier du notebook (mettre \".\" si le notebook est dans le même dossier que les CSV)\n",
    "BASE = Path(\".\")\n",
    "\n",
    "# Lister les CSV disponibles dans le dossier (⚠️ on liste un dossier, pas un fichier)\n",
    "csv_files = sorted(p.name for p in BASE.glob(\"*.csv\"))\n",
    "csv_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # I - Analyse descriptive des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes communes aux IMU (certains fichiers n'ont pas tout)\n",
    "COMMON = ['time','accX','accY','accZ','gyroX','gyroY','gyroZ','magX','magY','magZ','name']\n",
    "\n",
    "def read_common(path, nrows=None):\n",
    "    \"\"\"Charge un CSV et ne garde que les colonnes IMU connues + source.\"\"\"\n",
    "    df = pd.read_csv(path, nrows=nrows)\n",
    "    keep = [c for c in COMMON if c in df.columns]\n",
    "    df = df[keep].copy()\n",
    "    for c in df.columns:\n",
    "        if c not in ('time','name'):\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df['source'] = Path(path).name\n",
    "    return df\n",
    "\n",
    "def add_norms(df):\n",
    "    \"\"\"Ajoute des normes acc/gyro/mag si possible.\"\"\"\n",
    "    for name, cols in {\n",
    "        'acc_norm':  ['accX','accY','accZ'],\n",
    "        'gyro_norm': ['gyroX','gyroY','gyroZ'],\n",
    "        'mag_norm':  ['magX','magY','magZ'],\n",
    "    }.items():\n",
    "        have = [c for c in cols if c in df.columns]\n",
    "        if len(have)==3:\n",
    "            df[name] = np.sqrt((df[have]**2).sum(axis=1))\n",
    "    return df\n",
    "\n",
    "# Échantillon léger pour EDA\n",
    "eda_frames = []\n",
    "for f in csv_files:\n",
    "    if f.lower().startswith(\"quaternion\"):     # on exclut les quaternions pour l'instant\n",
    "        continue\n",
    "    try:\n",
    "        eda_frames.append(read_common(BASE/f, nrows=5000))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {f}: {e}\")\n",
    "\n",
    "eda = pd.concat(eda_frames, ignore_index=True, sort=False)\n",
    "eda = add_norms(eda)\n",
    "\n",
    "# Taille & colonnes par fichier\n",
    "sizes = (eda.groupby('source')['source']\n",
    "             .size()\n",
    "             .rename('rows')\n",
    "             .to_frame())\n",
    "sizes['cols_present'] = eda.groupby('source').apply(lambda g: list(g.columns))\n",
    "sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions (acc_norm / gyro_norm / mag_norm) par fichier\n",
    "for col in ['acc_norm','gyro_norm','mag_norm']:\n",
    "    if col in eda:\n",
    "        plt.figure()\n",
    "        for s, g in eda.groupby('source'):\n",
    "            g[col].dropna().sample(min(2000, len(g)), random_state=0).plot(kind='hist', bins=60, alpha=0.35, label=s)\n",
    "        plt.title(f\"Distribution de {col}\")\n",
    "        plt.xlabel(col); plt.ylabel(\"comptes\"); plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation robuste de la fréquence d'échantillonnage par fichier\n",
    "def estimate_hz(df):\n",
    "    if 'time' not in df:\n",
    "        return np.nan\n",
    "    # 1) Essai float (timestamps en secondes)\n",
    "    ts = pd.to_numeric(df['time'], errors='coerce')\n",
    "    if ts.notna().sum() >= 3:\n",
    "        d = np.diff(ts.dropna().values)\n",
    "        d = d[d>0]\n",
    "        if len(d): \n",
    "            med = np.median(d)\n",
    "            return round(1.0/med, 3) if med>0 else np.nan\n",
    "    # 2) Essai datetime\n",
    "    t = pd.to_datetime(df['time'], errors='coerce', utc=True, infer_datetime_format=True)\n",
    "    if t.notna().sum() >= 3:\n",
    "        d = np.diff(t.dropna().astype('int64').values/1e9)\n",
    "        d = d[d>0]\n",
    "        if len(d):\n",
    "            med = np.median(d)\n",
    "            return round(1.0/med, 3) if med>0 else np.nan\n",
    "    return np.nan\n",
    "\n",
    "hz = eda.groupby('source').apply(estimate_hz).rename('Hz').reset_index()\n",
    "hz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labellisation à partir du nom de fichier\n",
    "ANOMYMS = ['earthquake','hitting_arm','hitting_platform','extra_weigth','magnet']\n",
    "def label_from_name(name: str) -> int:\n",
    "    n = name.lower()\n",
    "    return int(any(k in n for k in ANOMYMS))\n",
    "\n",
    "# Charge tous les fichiers IMU (sauf quaternions pour l'instant) et prépare les features\n",
    "all_frames = []\n",
    "for f in csv_files:\n",
    "    if f.lower().startswith(\"quaternion\"):\n",
    "        continue\n",
    "    try:\n",
    "        df = read_common(BASE/f, nrows=None)   # mettre nrows=200_000 si on veux aller plus vite\n",
    "        df['label'] = label_from_name(f)\n",
    "        all_frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {f}: {e}\")\n",
    "\n",
    "raw = pd.concat(all_frames, ignore_index=True, sort=False)\n",
    "raw = add_norms(raw)\n",
    "\n",
    "# Colonnes features disponibles\n",
    "feature_cols = [c for c in ['accX','accY','accZ','gyroX','gyroY','gyroZ','magX','magY','magZ',\n",
    "                            'acc_norm','gyro_norm','mag_norm'] if c in raw.columns]\n",
    "raw = raw.dropna(subset=feature_cols, how='all').reset_index(drop=True)\n",
    "\n",
    "# Normalisation par fichier (évite les biais de calibration capteur)\n",
    "scalers = {}\n",
    "def scale_by_source(df, cols):\n",
    "    parts = []\n",
    "    for s, g in df.groupby('source', sort=False):\n",
    "        sc = StandardScaler()\n",
    "        g = g.copy()\n",
    "        g[cols] = sc.fit_transform(g[cols].fillna(method='ffill').fillna(method='bfill').fillna(0.0))\n",
    "        scalers[s] = sc\n",
    "        parts.append(g)\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "proc = scale_by_source(raw, feature_cols)\n",
    "proc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fenêtrage statistique (features sur fenêtres glissantes)\n",
    "WIN = 50          # 50 échantillons\n",
    "OVERLAP = 0.5     # 50% de recouvrement\n",
    "\n",
    "def window_features(df, cols, win=WIN, overlap=OVERLAP):\n",
    "    step = max(1, int(win*(1-overlap)))\n",
    "    N = len(df)\n",
    "    rows = []\n",
    "    for start in range(0, N - win + 1, step):\n",
    "        end = start + win\n",
    "        sl = df.iloc[start:end]\n",
    "        row = {}\n",
    "        for c in cols:\n",
    "            s = sl[c].values\n",
    "            row[f'{c}_mean'] = s.mean()\n",
    "            row[f'{c}_std']  = s.std()\n",
    "            row[f'{c}_min']  = s.min()\n",
    "            row[f'{c}_max']  = s.max()\n",
    "            row[f'{c}_rms']  = np.sqrt((s**2).mean())\n",
    "        # label majorité dans la fenêtre\n",
    "        row['label']  = int(sl['label'].mean() >= 0.5)\n",
    "        row['source'] = sl['source'].iloc[0]\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "blocks = []\n",
    "for s, g in proc.groupby('source', sort=False):\n",
    "    if len(g) >= WIN:\n",
    "        blocks.append(window_features(g, feature_cols, win=WIN, overlap=OVERLAP))\n",
    "\n",
    "dataset = pd.concat(blocks, ignore_index=True, sort=False)\n",
    "dataset['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - Formalisation du problème\n",
    "\n",
    "## 1) Contexte & but\n",
    "Nous disposons de mesures **IMU** d’un bras UR3e (accélération, gyroscope, magnétomètre) collectées lors de tâches normales (screwdriving, painting, pick-and-place) et lors d’**anomalies simulées** (earthquake, hitting_arm, hitting_platform, extra_weigth, magnet).  \n",
    "L’objectif opérationnel est une **détection d’anomalies en temps réel** compatible TinyML : déclencher une alerte fiable au fil de l’eau, avec peu de calcul et une latence faible.\n",
    "\n",
    "**Formulation ML** → *classification binaire fenêtre-par-fenêtre* :  \n",
    "- **Entrée** : descripteurs statistiques extraits sur des segments temporels glissants des signaux IMU.  \n",
    "- **Sortie** : `y ∈ {0,1}` avec `0 = normal`, `1 = anomalie`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Unité d’observation (fenêtrage temporel)\n",
    "Les fichiers sont échantillonnés à différentes fréquences (2/10/20 Hz). Pour homogénéiser l’analyse, on travaille sur des **fenêtres de `W` échantillons** (valeur par défaut `W = 50`).  \n",
    "Conséquences temporelles approximatives :\n",
    "- 20 Hz → 50 pts ≈ **2,5 s**  \n",
    "- 10 Hz → 50 pts ≈ **5 s**  \n",
    "- 2 Hz  → 50 pts ≈ **25 s** (fenêtre longue, à réduire si besoin pour ce cas)\n",
    "\n",
    "> Remarque : on peut utiliser un **recouvrement** (ex. 50 %) pour augmenter la granularité sans augmenter les coûts de labellisation.\n",
    "\n",
    "**Découpage en fenêtres** (sans recouvrement pour la baseline) :  \n",
    "Si un fichier a `N` lignes, le nombre de fenêtres est `⌊N / W⌋`.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Variables d’entrée (features)\n",
    "À partir des axes `(X,Y,Z)` on calcule d’abord les **normes** :\n",
    "\\[\n",
    "\\text{acc\\_norm}=\\sqrt{accX^2+accY^2+accZ^2},\\quad\n",
    "\\text{gyro\\_norm}=\\sqrt{gyroX^2+gyroY^2+gyroZ^2},\\quad\n",
    "\\text{mag\\_norm}=\\sqrt{magX^2+magY^2+magZ^2}.\n",
    "\\]\n",
    "\n",
    "Sur chaque fenêtre, pour chaque signal retenu (axes et/ou normes), on extrait des **statistiques robustes** :\n",
    "- moyenne, écart-type, min, max, RMS \\(\\left(\\sqrt{\\frac{1}{W}\\sum s^2}\\right)\\).\n",
    "\n",
    "> Ces features sont peu coûteuses, stables entre capteurs hétérogènes et adaptées à TinyML.\n",
    "\n",
    "**Optionnels (améliorations futures)** : énergie de bandes fréquentielles (FFT), dérivées/jerk, corrélations inter-axes, entropie, zcr (zero-crossing rate), etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Variable cible (labels)\n",
    "Pas de colonne `label` dans les fichiers → on utilise la **convention de nommage** :\n",
    "- `label = 1` si le nom du fichier contient : `earthquake`, `hitting_arm`, `hitting_platform`, `extra_weigth`, `magnet`.\n",
    "- `label = 0` sinon (fichiers IMU « normaux » : `IMU_2Hz`, `IMU_10Hz`, `IMU_Acc_Gyro_20Hz`, …).\n",
    "\n",
    "**Label de fenêtre** (majorité simple) :  \n",
    "si ≥ 50 % des points de la fenêtre sont `1` → fenêtre `1`, sinon `0`.  \n",
    "C’est un compromis simple qui stabilise le bruit instantané.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Pré-traitements retenus\n",
    "- **Casting** numérique robuste (`errors='coerce'`), suppression des lignes entièrement vides sur les colonnes IMU.\n",
    "- **Standardisation par source** (fichier) pour absorber les offsets capteurs :\n",
    "  \\[\n",
    "  z = \\frac{x-\\mu_{\\text{source}}}{\\sigma_{\\text{source}}}\n",
    "  \\]\n",
    "  Cette normalisation est apprise **séparément** pour chaque fichier afin d’éviter les fuites d’information.\n",
    "- **Agrégation fenêtre** → features statistiques (cf. §3).\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Jeu d’évaluation & fuite d’information\n",
    "Les échantillons d’une même source (fichier) sont **fortement corrélés**. On doit donc évaluer **par fichier**, pas par lignes aléatoires.\n",
    "\n",
    "- **Split** : `GroupShuffleSplit` avec `group = source` (le nom du fichier).  \n",
    "  Test ≈ 30 % des fichiers, Train ≈ 70 %.  \n",
    "- Variante robuste : **Leave-One-Group-Out** (LOGO) pour tester chaque fichier à tour de rôle (plus coûteux mais plus informatif).\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Métriques d’évaluation\n",
    "- **ROC-AUC** (global) pour mesurer la capacité de classement.  \n",
    "- **PR-AUC** / **F1** pour tenir compte du **déséquilibre** (anomalies rares).  \n",
    "- **Matrice de confusion** (TP/FP/FN/TN) pour fixer des seuils réalistes en exploitation (\\(P(\\text{FP})\\) acceptable vs rappel ciblé).\n",
    "\n",
    "**Cible industrielle** (exemple) :  \n",
    "- Rappel (anomalies) ≥ 95 % ;  \n",
    "- Taux de fausses alertes ≤ 2 % (à ajuster selon le contexte).\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Gestion du déséquilibre des classes\n",
    "- **Fenêtrage** et **majority-label** réduisent déjà l’extrême rareté point-par-point.  \n",
    "- Pendant l’entraînement : `class_weight='balanced'` ou sur-/sous-échantillonnage des fenêtres.  \n",
    "- Évaluation : toujours **stratifier par fichier** et **rapporter PR-AUC**.\n",
    "\n",
    "---\n",
    "\n",
    "## 9) Modèle baseline (Step 4, annoncé ici)\n",
    "- **RandomForest** (200 arbres) sur features statistiques → robuste, peu de réglages, interprétable via l’importance des variables.  \n",
    "- **Alternatives TinyML** :  \n",
    "  - **Logistic Regression** (faible empreinte mémoire),  \n",
    "  - **Tiny tree/oblique tree** (1–4 nœuds),  \n",
    "  - **Isolation Forest** (non supervisé) si on veut éviter les labels de nommage.\n",
    "\n",
    "---\n",
    "\n",
    "## 10) Contraintes temps réel & embarqué\n",
    "- **Latence** ≈ taille de fenêtre / fréquence (ex. 50 pts @ 20 Hz → 2,5 s).  \n",
    "- Si la latence doit être < 1 s, deux leviers :  \n",
    "  1) diminuer `W` (ex. 20–30) pour les fichiers 10/20 Hz,  \n",
    "  2) utiliser **fenêtres chevauchées** (stride plus petit) pour densifier les décisions sans augmenter la latence perçue.\n",
    "- **Coût de calcul** : features statistiques \\(O(W)\\), modèle léger (LR/mini-tree) pour MCU.\n",
    "\n",
    "---\n",
    "\n",
    "## 11) Critères de réussite (baseline)\n",
    "- Pipeline **reproductible** (mêmes splits, même normalisation par source).  \n",
    "- ROC-AUC ≥ 0,90 et PR-AUC convenable sur le test par fichier.  \n",
    "- Courbes ROC/PR + matrice de confusion + top features importances.  \n",
    "- Sauvegarde du modèle et des paramètres de normalisation (par source si nécessaire).\n",
    "\n",
    "---\n",
    "\n",
    "## 12) Limites & risques\n",
    "- **Labels dérivés du nom de fichier** → approximatifs si des segments « mixtes » existent ; la majority-rule l’atténue mais ne l’élimine pas.  \n",
    "- **Fréquences hétérogènes** → une fenêtre fixe correspond à des durées différentes ; à terme, utiliser une *durée* (en secondes) plutôt qu’un nombre d’échantillons.  \n",
    "- **Covariate shift** entre tâches (screwdriving vs painting) : valider par **LOGO** et, si besoin, ajouter des features spécifiques par tâche (ou un domaine-label si disponible).\n",
    "\n",
    "---\n",
    "\n",
    "## 13) Repro (configuration de référence)\n",
    "\n",
    "```python\n",
    "CONFIG = {\n",
    "  \"window_size\": 50,\n",
    "  \"window_overlap\": 0.0,        # 0.5 recommandé si besoin\n",
    "  \"features\": [\"mean\",\"std\",\"min\",\"max\",\"rms\"],\n",
    "  \"signals\": [\"acc_norm\",\"gyro_norm\",\"mag_norm\"],\n",
    "  \"split\": {\"method\":\"GroupShuffleSplit\", \"test_size\":0.3, \"group\":\"source\", \"seed\":42},\n",
    "  \"model\": {\"type\":\"RandomForest\", \"n_estimators\":200, \"random_state\":0, \"n_jobs\":-1},\n",
    "  \"metrics\": [\"classification_report\",\"confusion_matrix\",\"roc_auc\",\"pr_auc\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV - Modèle baseline + évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des features du modèle\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "\n",
    "\n",
    "feat_cols_model = [c for c in dataset.columns\n",
    "                   if c not in ('label','source')]\n",
    "\n",
    "X = dataset[feat_cols_model].values\n",
    "y = dataset['label'].values\n",
    "groups = dataset['source'].values\n",
    "\n",
    "# Split par fichier\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "Xtr, Xte = X[train_idx], X[test_idx]\n",
    "ytr, yte = y[train_idx], y[test_idx]\n",
    "\n",
    "# Baseline simple, robuste et rapide\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=0, n_jobs=-1)\n",
    "clf.fit(Xtr, ytr)\n",
    "\n",
    "pred = clf.predict(Xte)\n",
    "proba = clf.predict_proba(Xte)[:,1]\n",
    "\n",
    "print(\"=== Rapport classification (test) ===\")\n",
    "print(classification_report(yte, pred, digits=3))\n",
    "\n",
    "print(\"=== Matrice de confusion ===\")\n",
    "print(confusion_matrix(yte, pred))\n",
    "\n",
    "# ROC-AUC / PR-AUC (protégé si une seule classe en test)\n",
    "try:\n",
    "    roc = roc_auc_score(yte, proba)\n",
    "    pr  = average_precision_score(yte, proba)\n",
    "    print(f\"ROC-AUC : {roc:.3f}\")\n",
    "    print(f\"PR-AUC  : {pr:.3f}\")\n",
    "\n",
    "    RocCurveDisplay.from_predictions(yte, proba)\n",
    "    plt.title(\"ROC — RandomForest baseline\")\n",
    "    plt.show()\n",
    "\n",
    "    PrecisionRecallDisplay.from_predictions(yte, proba)\n",
    "    plt.title(\"Precision–Recall — RandomForest baseline\")\n",
    "    plt.show()\n",
    "except ValueError as e:\n",
    "    print(\"Courbes ROC/PR non calculables :\", e)\n",
    "\n",
    "# (Option) Top features pour interpréter la baseline\n",
    "import pandas as pd\n",
    "imp = pd.Series(clf.feature_importances_, index=feat_cols_model).sort_values(ascending=False).head(15)\n",
    "plt.figure()\n",
    "imp.plot(kind=\"barh\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top feature importances — RandomForest\")\n",
    "plt.xlabel(\"importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V - Grid Search + Ensembles (LAB 6 appliqué au projet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reprise des features / labels / groupes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols_model = [c for c in dataset.columns\n",
    "                   if c not in (\"label\", \"source\")]\n",
    "\n",
    "X = dataset[feat_cols_model].values\n",
    "y = dataset[\"label\"].values\n",
    "groups = dataset[\"source\"].values\n",
    "\n",
    "# Split \"externe\" par fichier : train vs test \n",
    "gss_outer = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(gss_outer.split(X, y, groups))\n",
    "\n",
    "Xtr, Xte = X[train_idx], X[test_idx]\n",
    "ytr, yte = y[train_idx], y[test_idx]\n",
    "groups_tr = groups[train_idx]\n",
    "\n",
    "print(\"Train size :\", Xtr.shape, \" Test size :\", Xte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) GridSearch sur RandomForest (baseline optimisée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base = RandomForestClassifier(\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"   # important avec le déséquilibre de classes\n",
    ")\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# CV interne par fichier aussi (GroupShuffleSplit)\n",
    "cv_inner = GroupShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=cv_inner,\n",
    "    scoring=\"f1\",      # meilleur que accuracy sur ce type de problème\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "rf_grid.fit(Xtr, ytr, groups=groups_tr)\n",
    "\n",
    "print(\"\\n=== RandomForest — meilleurs hyperparamètres (CV interne) ===\")\n",
    "print(rf_grid.best_params_)\n",
    "print(f\"Best CV F1-score: {rf_grid.best_score_:.3f}\")\n",
    "\n",
    "best_rf = rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Helper d'évaluation pour tous les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def eval_model(name, model, Xtr, ytr, Xte, yte):\n",
    "    \"\"\"Fit + prédiction + métriques + temps, pour un modèle donné.\"\"\"\n",
    "    t0 = time.time()\n",
    "    model.fit(Xtr, ytr)\n",
    "    fit_time = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    y_pred = model.predict(Xte)\n",
    "    infer_time = time.time() - t1\n",
    "\n",
    "    # Probabilités si dispo (sinon None)\n",
    "    try:\n",
    "        y_proba = model.predict_proba(Xte)[:, 1]\n",
    "    except AttributeError:\n",
    "        y_proba = None\n",
    "\n",
    "    acc  = accuracy_score(yte, y_pred)\n",
    "    f1   = f1_score(yte, y_pred)\n",
    "    prec = precision_score(yte, y_pred)\n",
    "    rec  = recall_score(yte, y_pred)\n",
    "\n",
    "    print(f\"\\n================ {name} ================\")\n",
    "    print(classification_report(yte, y_pred, digits=3))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(yte, y_pred))\n",
    "\n",
    "    roc = pr = None\n",
    "    if y_proba is not None and len(np.unique(yte)) == 2:\n",
    "        roc = roc_auc_score(yte, y_proba)\n",
    "        pr  = average_precision_score(yte, y_proba)\n",
    "        print(f\"ROC-AUC: {roc:.3f}\")\n",
    "        print(f\"PR-AUC : {pr:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"roc_auc\": roc,\n",
    "        \"pr_auc\": pr,\n",
    "        \"fit_time_s\": fit_time,\n",
    "        \"infer_time_s\": infer_time\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# Évaluation de la baseline optimisée RandomForest\n",
    "results.append(eval_model(\"RandomForest (tuned)\", best_rf, Xtr, ytr, Xte, yte))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Ensemble 1 : Bagging SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.4 Ensemble 1 : Bagging SVM ( ---\n",
    "\n",
    "svm_base = SVC(\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    C=1.0,\n",
    "    kernel=\"rbf\",\n",
    "    gamma=\"scale\"\n",
    ")\n",
    "\n",
    "bag_svm = BaggingClassifier(\n",
    "    estimator=svm_base,\n",
    "    n_estimators=5,      # ne pas mettre trop haut pour ne pas tuer le PC\n",
    "    max_samples=0.7,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "results.append(\n",
    "    eval_model(\"Bagging SVM (no tuning)\", bag_svm, Xtr, ytr, Xte, yte)\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5.5 Ensemble 2 : Bagging Decision Tree ---\n",
    "\n",
    "tree_base = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    max_depth=5,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "\n",
    "bag_tree = BaggingClassifier(\n",
    "    estimator=tree_base,\n",
    "    n_estimators=15,     # ne pas mettre trop haut pour ne pas tuer le PC\n",
    "    max_samples=0.7,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "results.append(\n",
    "    eval_model(\"Bagging Tree (no tuning)\", bag_tree, Xtr, ytr, Xte, yte)\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5.6 Ensemble 3 : Voting (RF + Bagging SVM + Bagging Tree) ---\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rf\", best_rf),          \n",
    "        (\"bag_svm\", bag_svm),\n",
    "        (\"bag_tree\", bag_tree)\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "results.append(\n",
    "    eval_model(\"Voting (RF + BagSVM + BagTree)\", voting_clf, Xtr, ytr, Xte, yte)\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5.7 Tableau récap + barplot ---\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values(\"f1\", ascending=False))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(results_df[\"model\"], results_df[\"accuracy\"])\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.ylabel(\"Accuracy (test)\")\n",
    "plt.title(\"Comparison of models on IMU anomaly detection\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
